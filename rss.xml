<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>John Moeller</title>
        <link></link>
        <description><![CDATA[John Moeller (Updates)]]></description>
        <atom:link href="/rss.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Thu, 01 Sep 2016 00:00:00 UT</lastBuildDate>
        <item>
    <title>Continuous Kernel Learning</title>
    <link>/pubs/2016-09-01-ckl.html</link>
    <description><![CDATA[<div class="blog-post">
  <h2 class="blog-post-title">
    Continuous Kernel Learning
  </h2>
  <p class="blog-post-meta">
    Published 2016-09
    
      by John Moeller, Vivek Srikumar, Sarathkrishna Swaminathan, Suresh Venkatasubramanian, Dustin Webb
    
    
  </p>
  <p>Kernel learning is the problem of determining the best kernel (either from a dictionary of fixed kernels, or from a smooth space of kernel representations) for a given task. In this paper, we describe a new approach to kernel learning that establishes connections between the Fourier-analytic representation of kernels arising out of Bochner's theorem and a specific kind of feed-forward network using cosine activations. We analyze the complexity of this space of hypotheses and demonstrate empirically that our approach provides scalable kernel learning superior in quality to prior approaches.</p>
</div>
]]></description>
    <pubDate>Thu, 01 Sep 2016 00:00:00 UT</pubDate>
    <guid>/pubs/2016-09-01-ckl.html</guid>
    <dc:creator>John Moeller</dc:creator>
</item>

    </channel>
</rss>
